# A study on the inherent bias of large language models

By getting LLMs' (currently ChatGPT's) responses to various prompts, and measuring those responses through sentiment analysis or other methods, this study aims to measure various types of bias present in LLMs.


## Timeline

So far (roughly 2 weeks in) this project has found clear political preference in chatGPT's poem writing about various presidents, as well as its descriptions of the same presidents. Data collected through the analysis of ~5000 of responses of chatGPT is presented through histograms as well as time-based box plots.

In the very near future the project will include other political questions (currently focusing on gun rights) and figure out where chatGPT stands relative to the population. Although many other types of bias (other than political) in chatGPT have already been well documented, this project aims to approach traditional analysis methods in new ways as well.

Ultimately, this study plans to encompass more LLMs than just chatGPT, and compare the preference of those LLMs to the preference of the population as a whole to decide if chatGPT's preference differs from the general population's, and if it does where its bias may have originated. Lastly, the study will look into how this bias can be approached and solved in the future.


## Author

- [@noahsbates](https://www.github.com/noahsbates)
