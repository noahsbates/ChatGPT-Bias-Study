# A study on the inherent bias of large language models

By getting LLMs' (currently ChatGPT's) responces to various prompts, and measuring those responces through sentiment analysis or other methods, this study aims to mesure various types of bias present in LLMs.


## Timeline

So far (roughly 2 weeks in) this project has found clear political prefrence in chat GPT's poem writing about various presidents, as well as it's descriptions of the same presidents. Data collected through the analysis of ~5000 of responces of chatGPT is presented through histograms as well as time-based box plots.

In the near future the project will include other political questions (currently focusing on gun rights) and figure out where chatGPT stands. 

Ultimately, this study plans to encompass more LLMs than just chatGPT, and compare the prefrence of those LLMs to the prefrence of the population as a whole to decide if chatGPT's prefrence differs from the general population's, and if not where it's bias may have origionated. Lastly, the study will look into how this bias can be approached and solved in the future.


## Author

- [@noahsbates](https://www.github.com/noahsbates)